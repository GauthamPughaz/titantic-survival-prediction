{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Storing the passenger_ids for submission\n",
    "passenger_ids = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the counts of survived and dead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the count of missing values of each feature in train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the count of missing values of each feature in test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying some statistical functions on train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying some statistical functions on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Passenger class **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_survived_vs_feature(feature, df=train_df, labels={}):\n",
    "\n",
    "    survived_mapping = df['Survived'].map({0: 'Dead', 1: 'Survived'})\n",
    "\n",
    "    fig = px.histogram(df, x=survived_mapping, width=800, color=feature, labels=labels)\n",
    "    fig.update_layout(\n",
    "        bargap=0.2,\n",
    "        xaxis_title_text='Survived',\n",
    "        yaxis_title_text='Survived count'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "hist_survived_vs_feature('Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_survived_vs_feature('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x='Age', color='Survived', barmode='overlay')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Sibling and Spouse count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_survived_vs_feature('SibSp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Parent and Children count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_survived_vs_feature('Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Fare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x='Fare', color='Survived', barmode='overlay')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Cabin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[train_df['Cabin'].notnull()]\n",
    "cabin_initials = df['Cabin'].map(lambda x: x[0])\n",
    "\n",
    "hist_survived_vs_feature(cabin_initials, df=df, labels={'color': 'cabin'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an histogram for Survived with respect to Embarked station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[train_df['Embarked'].notnull()]\n",
    "hist_survived_vs_feature('Embarked', df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting the titles from passenger names and one-hot encoding them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the train and test data into a single dataset\n",
    "dataset = [train_df, test_df]\n",
    "\n",
    "# Preprocessing feature 'Name'\n",
    "\n",
    "for df in dataset:\n",
    "    # Extracting title\n",
    "    df['Title'] = df['Name'].map(lambda x: re.search(r' ([A-Za-z]+)\\.', x).group().strip().replace('.', ''))\n",
    "\n",
    "# Unique titles in train data\n",
    "train_df['Title'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unique titles in test data\n",
    "\n",
    "test_df['Title'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Mr, Miss, Mrs, Master and rest to numerical values\n",
    "title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 5, 'Col': 5,\n",
    "                 'Major': 5, 'Mlle': 5, 'Ms': 5, 'Countess': 5, 'Lady': 5, 'Capt': 5,\n",
    "                 'Jonkheer': 5, 'Don': 5, 'Sir': 5, 'Mme': 5}\n",
    "\n",
    "for df in dataset:\n",
    "    df['Title'] = df['Title'].map(title_mapping)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dummies(feature_name):\n",
    "    global dataset\n",
    "    \n",
    "    new_train_df = pd.concat([train_df, pd.get_dummies(train_df[feature_name], prefix=feature_name)], axis=1)\n",
    "    new_test_df = pd.concat([test_df, pd.get_dummies(test_df[feature_name], prefix=feature_name)], axis=1)\n",
    "    dataset = [new_train_df, new_test_df]\n",
    "    \n",
    "    return new_train_df, new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the one-hot encoded values with the train and test dataframes\n",
    "train_df, test_df = concat_dummies('Title')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the passenger gender to numerical values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing feature 'Sex'\n",
    "\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "\n",
    "for df in dataset:\n",
    "    df['Sex'] = df['Sex'].map(sex_mapping)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning Age feature based on the trend in histogram and one-hot encoding them**\n",
    "\n",
    "* 0 - 5: Age Group 1\n",
    "* 6 - 11: Age Group 2\n",
    "* 12 - 17: Age Group 3\n",
    "* 18 - 25: Age Group 4\n",
    "* 26 - 47: Age Group 5\n",
    "* 48 - 61: Age Group 6\n",
    "* 61 - 80: Age Group 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing feature 'Age'\n",
    "\n",
    "age_bins = [0, 5.99, 11.9, 17.9, 25.9, 47.9, 61.9, 80]\n",
    "age_labels = [i for i in range(1, 8)]\n",
    "\n",
    "for df in dataset:\n",
    "    # Filling the missing values in each dataset with median of corresponding 'Title' feature\n",
    "    df['Age'] = df['Age'].fillna(df.groupby('Title')['Age'].transform('median'))\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the one-hot encoded values with the train and test dataframes\n",
    "train_df, test_df = concat_dummies('AgeGroup')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the parent/children count and sibling/spouse count to 0 - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing features 'Parch' and 'SipSp'\n",
    "\n",
    "def scale_feature(feature):\n",
    "    result = []\n",
    "    \n",
    "    # Applying min-max scaling to the 'Parch' and 'SipSp' features\n",
    "    for df in dataset:\n",
    "        feature_val = df[feature]\n",
    "        max_val = feature_val.max()\n",
    "        min_val = feature_val.min()\n",
    "        scaled_feature = (feature_val - min_val) / (max_val - min_val)\n",
    "        result.append(scaled_feature)\n",
    "        \n",
    "    return result\n",
    "\n",
    "train_df['SibSp'], test_df['SibSp'] = scale_feature('SibSp')\n",
    "train_df['Parch'], test_df['Parch'] = scale_feature('Parch')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the passenger fare to 0 - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing feature 'Fare'\n",
    "\n",
    "# Filling the missing values with the median of the corresponding passenger class\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df.groupby('Pclass')['Fare'].transform('median'))\n",
    "train_df['Fare'], test_df['Fare'] = scale_feature('Fare')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding the embarked station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing feature 'Embarked'\n",
    "\n",
    "# Visualizing the count of passenger's embarkment across different passenger classes using bar chart\n",
    "df = train_df[train_df['Embarked'].notnull()]\n",
    "class_count = df.groupby(['Pclass', 'Embarked'])['Embarked'].count()\n",
    "C_count = class_count.loc[([1, 2, 3], 'C')]\n",
    "Q_count = class_count.loc[([1, 2, 3], 'Q')]\n",
    "S_count = class_count.loc[([1, 2, 3], 'S')]\n",
    "\n",
    "p_class = [1, 2, 3]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=p_class, y=C_count.tolist(), name='C'))\n",
    "fig.add_trace(go.Bar(x=p_class, y=Q_count.tolist(), name='Q'))\n",
    "fig.add_trace(go.Bar(x=p_class, y=S_count.tolist(), name='S'))\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis_title_text='Passenger class',\n",
    "    yaxis_title_text='Embarked station count'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Getting the same figure using histogram\n",
    "fig = px.histogram(df, x='Pclass', color='Embarked')\n",
    "fig.update_layout(\n",
    "    bargap=0.2,\n",
    "    xaxis_title_text='Passenger class',\n",
    "    yaxis_title_text='Embarked station count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values with 'S' station as it covers 50% of the count on each class\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
    "# Concatenating the one-hot encoded values with the train and test dataframes\n",
    "train_df, test_df = concat_dummies('Embarked')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "train_df = train_df.drop(['PassengerId', 'Name', 'Age', 'Ticket', 'Cabin', 'Embarked',\n",
    "                          'Title', 'AgeGroup'], axis=1)\n",
    "test_df = test_df.drop(['PassengerId', 'Name', 'Age', 'Ticket', 'Cabin', 'Embarked',\n",
    "                          'Title', 'AgeGroup'], axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Passenger class is not one-hot encoded to maintain the ordinality of the feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, 1:].values\n",
    "y = train_df['Survived'].values\n",
    "\n",
    "# Splitting the train data into train and validation sets \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_val.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Keras sequential model for the binary classification problem\n",
    "model = tf.keras.Sequential()\n",
    "# Adding dropout layer to avoid overfitting the train data\n",
    "model.add(tf.keras.layers.Dropout(0.25, input_shape=[20]))\n",
    "model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Using Adam optimizer with custom learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 10 epochs\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=10,\n",
    "    batch_size=1,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting 'Survived' for test data\n",
    "prediction = model.predict(X_test)\n",
    "# Rounding the predictions to either 0 or 1\n",
    "rounded_prediction = np.where(prediction >= 0.5, 1, 0).flatten()\n",
    "\n",
    "# Creating a dataframe for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': rounded_prediction\n",
    "})\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the dataframe as a CSV file for submission\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# clf = LinearSVC(C=5, max_iter=10000)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.score(X_val, y_val)\n",
    "# rounded_prediction = clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
